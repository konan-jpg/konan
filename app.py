import streamlit as st
import pandas as pd
import glob
import os
from datetime import datetime
import altair as alt

# --------------------------------------------------------------------------
# 1. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
# --------------------------------------------------------------------------
st.set_page_config(layout="wide", page_title="ì¶”ì„¸ì¶”ì¢… ìŠ¤ìºë„ˆ")

@st.cache_data(ttl=300)
def load_data():
    """
    data/ í´ë” ë‚´ì˜ ìµœì‹  ê²°ê³¼ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    ë§Œì•½ í•©ì³ì§„ íŒŒì¼ì´ ì—†ìœ¼ë©´ data/partial/ ë‚´ì˜ chunk íŒŒì¼ë“¤ì„ ì½ì–´ í•©ì¹©ë‹ˆë‹¤.
    """
    # 1ìˆœìœ„: ì´ë¯¸ í•©ì³ì§„ ìµœì¢… íŒŒì¼ ì°¾ê¸° (ë‚ ì§œë³„ íŒŒì¼)
    merged_files = glob.glob("data/scanner_output*.csv")
    merged_files = [f for f in merged_files if 'chunk' not in f]  # chunk íŒŒì¼ ì œì™¸
    
    if merged_files:
        # íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œí•´ì„œ ê°€ì¥ ìµœì‹  ê²ƒ ì„ íƒ
        # scanner_output_2026-01-17.csv ê°™ì€ í˜•ì‹ ê°€ì •
        def extract_date(filename):
            try:
                # íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ë¶€ë¶„ ì¶”ì¶œ (YYYY-MM-DD)
                parts = os.path.basename(filename).replace('.csv', '').split('_')
                if len(parts) >= 3:
                    return parts[-1]  # ë§ˆì§€ë§‰ ë¶€ë¶„ì´ ë‚ ì§œ
                return '0000-00-00'
            except:
                return '0000-00-00'
        
        latest_file = max(merged_files, key=extract_date)
        df = pd.read_csv(latest_file)
        return df, os.path.basename(latest_file)

    # 2ìˆœìœ„: data/partial/ ë‚´ì˜ chunk íŒŒì¼ ì°¾ê¸° (fallback)
    chunk_files = glob.glob("data/partial/scanner_output*chunk*.csv")
    
    if chunk_files:
        df_list = []
        for f in sorted(chunk_files):  # ìˆœì„œëŒ€ë¡œ ì½ê¸°
            try:
                sub_df = pd.read_csv(f)
                df_list.append(sub_df)
            except Exception as e:
                st.warning(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {f} - {e}")
                continue
        
        if df_list:
            final_df = pd.concat(df_list, ignore_index=True)
            # ì¤‘ë³µ ì œê±° (code ì»¬ëŸ¼ ê¸°ì¤€)
            if 'code' in final_df.columns:
                final_df.drop_duplicates(subset=['code'], keep='first', inplace=True)
            
            st.info(f"ğŸ“¦ Partial íŒŒì¼ {len(df_list)}ê°œë¥¼ í•©ì³ì„œ í‘œì‹œí•©ë‹ˆë‹¤ (ì´ {len(final_df)}ê°œ ì¢…ëª©)")
            return final_df, f"Merged from {len(df_list)} chunks"

    return None, None

# --------------------------------------------------------------------------
# 2. ë©”ì¸ ì•± ë¡œì§
# --------------------------------------------------------------------------
st.title("ğŸ” ì¶”ì„¸ì¶”ì¢… ìŠ¤ìºë„ˆ (ì¼ë´‰/ì¥ë§ˆê°)")

df, filename = load_data()

if df is None:
    st.error("âŒ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. GitHub Actions ì‹¤í–‰ í›„ data/ ë˜ëŠ” data/partial/ì— íŒŒì¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
    st.info("ğŸ’¡ GitHub ë ˆí¬ì§€í† ë¦¬ì—ì„œ ì›Œí¬í”Œë¡œê°€ ì •ìƒ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

st.success(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {filename} (ì´ {len(df)}ê°œ ì¢…ëª©)")

# ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
if 'total_score' in df.columns:
    df = df.sort_values(by='total_score', ascending=False).reset_index(drop=True)
else:
    st.error("total_score ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# --------------------------------------------------------------------------
# 3. í•„í„°ë§ ë° í…Œì´ë¸” í‘œì‹œ
# --------------------------------------------------------------------------
min_score = st.sidebar.slider("ìµœì†Œ ì ìˆ˜", 0, 100, 50)
filtered_df = df[df['total_score'] >= min_score].copy()

st.subheader(f"ğŸ† ìƒìœ„ ë­í‚¹ ì¢…ëª© ({len(filtered_df)}ê°œ)")

# í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ (ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ)
display_cols = ['rank', 'code', 'name', 'close', 'total_score', 'trend_score', 'vol_score']
display_cols = [col for col in display_cols if col in filtered_df.columns]

st.dataframe(
    filtered_df[display_cols],
    use_container_width=True,
    height=400
)

# --------------------------------------------------------------------------
# 4. ì°¨íŠ¸ ìƒì„¸ ë³´ê¸° (ì¢…ëª© ì„ íƒ)
# --------------------------------------------------------------------------
if len(filtered_df) > 0:
    st.subheader("ğŸ“ˆ ì¢…ëª© ìƒì„¸ ë¶„ì„")
    
    # ì„ íƒ ë°•ìŠ¤: "ì´ë¦„ (ì½”ë“œ)" í˜•ì‹
    option_list = [f"{row['name']} ({row['code']})" for _, row in filtered_df.iterrows()]
    selected_option = st.selectbox("ì¢…ëª© ì„ íƒ", option_list)
    
    if selected_option:
        # "ì‚¼ì„±ì „ì (005930)" -> "005930" ì¶”ì¶œ
        selected_code = selected_option.split('(')[-1].replace(')', '').strip()
        
        # í•´ë‹¹ ì¢…ëª© ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        row = df[df['code'] == selected_code].iloc[0]
        
        col1, col2, col3 = st.columns(3)
        col1.metric("í˜„ì¬ê°€", f"{row['close']:,.0f}ì›")
        col2.metric("ì´ì ", f"{row['total_score']:.0f}ì ")
        col3.metric("ì¶”ì„¸ ì ìˆ˜", f"{row['trend_score']:.0f}ì ")
        
        # ì¶”ê°€ ì •ë³´ í‘œì‹œ
        st.markdown("### ğŸ“Š ì¢…ëª© ìƒì„¸ ì •ë³´")
        info_cols = st.columns(2)
        
        with info_cols[0]:
            if 'vol_score' in row:
                st.write(f"**ê±°ë˜ëŸ‰ ì ìˆ˜**: {row['vol_score']:.0f}ì ")
            if 'rank' in row:
                st.write(f"**ìˆœìœ„**: {row['rank']}ìœ„")
        
        with info_cols[1]:
            if 'ma20' in df.columns and 'ma20' in row:
                st.write(f"**20ì¼ ì´í‰ì„ **: {row['ma20']:,.0f}ì›")
            if 'ma60' in df.columns and 'ma60' in row:
                st.write(f"**60ì¼ ì´í‰ì„ **: {row['ma60']:,.0f}ì›")
        
        st.info(f"ğŸ’¡ ì„ íƒëœ ì¢…ëª©: **{row['name']}** - ìƒì„¸ ì°¨íŠ¸ëŠ” OHLCV ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
else:
    st.warning("ì¡°ê±´ì— ë§ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”.")

# --------------------------------------------------------------------------
# 5. í‘¸í„°
# --------------------------------------------------------------------------
st.markdown("---")
st.caption(f"ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | ë°ì´í„°: {filename}")
